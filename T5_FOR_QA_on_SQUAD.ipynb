{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c5fb76",
   "metadata": {},
   "source": [
    "# Дипломный AL project студента Жукова Егора\n",
    "\n",
    "<p>\n",
    "    <strong>Тема: Разработка pipline модели для QA</strong>\n",
    "</p>\n",
    "<p>\n",
    "    Описание задачи:\n",
    "    \n",
    "    Есть открытый набор данных SBERSQUAD, который содержит данные энцеклопидического толка. Есть отрывок (контекст) статьи, ряд вопросов по тексту отрывка,\n",
    "    а так же ответы из текста. Необходимо подобрать архитектуру модели, разработать пайлпайн ее обучения, с целью научить модель отвечать на вопросы, находя ответы в контексте.\n",
    "    \n",
    "    Преимущества реализации:\n",
    "    Уникальностью решения является возможность модели извлекать ответы из контекста, который она не видела на обучение. При этом ответы максимально приближенны к контексту, как будто у нас Reader система, но при этом в основном лишены недостатков Generator системы (генерация \"бреда\"). Это позволяет использовать данный подход в большом спектре бизнес задач.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    \n",
    "    Данные:   \n",
    "    \n",
    "    https://huggingface.co/datasets/sberquad\n",
    "    https://arxiv.org/abs/1912.09723\n",
    "    \n",
    "    name\ttrain\tvalidation\ttest\n",
    "    plain_text\t45328\t5036\t23936\n",
    "    \n",
    "    размер обучающей выборки превышает 45 000 строк\n",
    "    Context - не уникален\n",
    "    Question - уникален\n",
    "    Answer - уникален соответсвует вопросу\n",
    "</p>\n",
    "<p>\n",
    "    Архитектура:\n",
    "    \n",
    "    После изучения вопроса остановился на архитектуре T5\n",
    "    https://arxiv.org/pdf/1910.10683.pdf\n",
    "    \n",
    "    Предобученная модель от Sberbank AL\n",
    "    https://huggingface.co/sberbank-ai/ruT5-base\n",
    "    \n",
    "</p>\n",
    "<p>\n",
    "    Допущения:\n",
    "    \n",
    "    Я не стал предобрабатывать текст. Это поле для экспериментов, но в случае с энциклопедией может потерятся смысл имен и названий.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46787d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорты необходимых библиотек\n",
    "import transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# удобный класс для настроек\n",
    "from types import SimpleNamespace\n",
    "# метрика, не совсем подходит для русского языка\n",
    "from rouge import Rouge\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f822046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mresquilleur\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tqdm.pandas()\n",
    "wandb.login()\n",
    "# собираем параметры в одно место\n",
    "cfg = SimpleNamespace()\n",
    "cfg.model_name = \"sberbank-ai/ruT5-base\"\n",
    "cfg.batch_size = 4\n",
    "cfg.epoch = 3\n",
    "cfg.learning_rate = 1e-5\n",
    "cfg.source_max_len = 439\n",
    "cfg.target_max_len = 30\n",
    "cfg.seed = 2022\n",
    "cfg.path_of_model = 'MODELS/'\n",
    "cfg.apex = True\n",
    "cfg.max_grad_norm = 1.0\n",
    "cfg.n_accumulate = 1\n",
    "cfg.num_warmup_steps = 0\n",
    "cfg.eps = 1e-6\n",
    "cfg.betas = (0.9, 0.999)\n",
    "cfg.num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa6d1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обеспечиваем воспроизводимость результатов\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe87c0",
   "metadata": {},
   "source": [
    "# 1. Загрузка и обработка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3db3b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset sberquad (C:\\Users\\bitzh\\.cache\\huggingface\\datasets\\sberquad\\sberquad\\1.0.0\\62115d937acf2634cfacbfee10c13a7ee39df3ce345bb45af7088676f9811e77)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b42578c9e64a9c9b5cf1e5934a13ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('sberquad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c53fbb",
   "metadata": {},
   "source": [
    "## 1.1. Формирование наборов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de6cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция конвертации данных из формата набора в обычный датафрейм для удобства и читаемости данных (нам не нужны позиции ответов)\n",
    "def DataPrepareToSQUAD(dataset):\n",
    "    # train dataframe\n",
    "    tdf = dataset[\"train\"].to_pandas().drop(['id', 'title'], axis=1)\n",
    "    tdf['answers'] = [x['text'][0] for x in dataset['train']['answers']]\n",
    "    # validate dataframe\n",
    "    vdf = dataset[\"validation\"].to_pandas().drop(['id', 'title'], axis=1)\n",
    "    vdf['answers'] = [x['text'][0] for x in dataset['validation']['answers']]\n",
    "    return tdf, vdf\n",
    "\n",
    "train_data, val_data = DataPrepareToSQUAD(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a98ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.sample(500).reset_index(drop=True)\n",
    "# val_data = val_data.sample(100).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb9d95",
   "metadata": {},
   "source": [
    "## 1.2. EDA максимальной длины последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e249f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим токенайзер\n",
    "tokenizer = T5Tokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b9ddb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b04ad06ef94a5881d5b77566a45e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff2b589e8624e83bdeb0c94d9ff3d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4b997c78584c2e86a57f0f477f022a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "data_len = pd.concat([train_data, val_data], axis=0).reset_index(drop=True)\n",
    "\n",
    "def get_token_len(x):\n",
    "    x = tokenizer.encode_plus(x,\n",
    "                          add_special_tokens=True,\n",
    "                          max_length=512,\n",
    "                          return_token_type_ids=False,\n",
    "                          pad_to_max_length=False,\n",
    "                          return_attention_mask=False,\n",
    "                          truncation=True\n",
    "                          )\n",
    "    return len(x['input_ids'])\n",
    "\n",
    "data_len['context_token_len'] = data_len['context'].progress_apply(get_token_len)\n",
    "data_len['question_token_len'] = data_len['question'].progress_apply(get_token_len)\n",
    "data_len['qc_token_len'] = data_len['question_token_len'] + data_len['context_token_len']\n",
    "data_len['answers_token_len'] = data_len['answers'].progress_apply(get_token_len)\n",
    "\n",
    "cfg.source_max_len = int(data_len['qc_token_len'].describe(percentiles=[0.995])['99.5%'])\n",
    "print(cfg.source_max_len)\n",
    "\n",
    "cfg.target_max_len = int(data_len['answers_token_len'].describe(percentiles=[0.995])['99.5%'])\n",
    "print(cfg.target_max_len)\n",
    "\n",
    "del data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ece874-433a-498e-9664-4624348b45fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b882df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5DataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Создание пользовательского набора данных для чтения набора данных и\n",
    "    загрузки его в загрузчик данных для передачи его во вход\n",
    "    нейронной сети для тонкой настройки модели\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, dataframe: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer, question_len: int = 0,\n",
    "        answers_len: int = 0,\n",
    "        switch: bool = True):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.question_len = question_len\n",
    "        self.answers_len = answers_len\n",
    "        self.question = self.data[\"question\"]\n",
    "        self.context = self.data[\"context\"]\n",
    "        self.switch = switch\n",
    "        if self.switch:\n",
    "            self.answers = self.data[\"answers\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "\n",
    "        question = str(self.question[idx])\n",
    "        context = str(self.context[idx])\n",
    "        answers = str(self.answers[idx])\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            question,\n",
    "            context,\n",
    "            max_length=self.question_len,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            truncation=\"only_second\",\n",
    "        )\n",
    "        \n",
    "        samples = {\n",
    "            \"input_ids\": inputs[\"input_ids\"],\n",
    "            \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        }\n",
    "\n",
    "        if self.switch:\n",
    "            targets = self.tokenizer.encode_plus(\n",
    "                answers,\n",
    "                max_length=self.answers_len,\n",
    "                return_attention_mask=True,\n",
    "                add_special_tokens=True,\n",
    "                truncation=True,\n",
    "            )\n",
    "            target_ids = targets[\"input_ids\"]\n",
    "            samples[\"target_ids\"] = target_ids\n",
    "            samples[\"answers\"] = answers\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03db96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Динамический паддинг\n",
    "class Collate:\n",
    "    def __init__(self, tokenizer, isTrain=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.isTrain = isTrain\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        output = dict()\n",
    "        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n",
    "        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n",
    "        if self.isTrain:\n",
    "            output[\"target_ids\"] = [sample[\"target_ids\"] for sample in batch]\n",
    "            output[\"answers\"] = [sample[\"answers\"] for sample in batch]\n",
    "        # вычисляем максимальную длину токена в батче\n",
    "        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n",
    "\n",
    "        # add padding\n",
    "        if self.tokenizer.padding_side == \"right\":\n",
    "            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n",
    "            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n",
    "        else:\n",
    "            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n",
    "            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n",
    "\n",
    "        # convert to tensors\n",
    "        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n",
    "        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n",
    "        \n",
    "        # если тренируем то делаем тоже самое с таргетами\n",
    "        if self.isTrain:\n",
    "            batch_max = max([len(ids) for ids in output[\"target_ids\"]])\n",
    "\n",
    "            if self.tokenizer.padding_side == \"right\":\n",
    "                output[\"target_ids\"] = [s + (batch_max - len(s)) * [-100] for s in output[\"target_ids\"]]\n",
    "            else:\n",
    "                output[\"target_ids\"] = [(batch_max - len(s)) * [-100] + s for s in output[\"target_ids\"]]\n",
    "            output[\"target_ids\"] = torch.tensor(output[\"target_ids\"], dtype=torch.long)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf2cbc",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91332b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(tokenizer, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=cfg.apex)\n",
    "    losses = []\n",
    "    for i, data in enumerate(tqdm(loader), 0):\n",
    "        \n",
    "        inputs_ids = data[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        inputs_mask = data[\"attention_mask\"].to(device, dtype=torch.long)        \n",
    "        target_ids = data[\"target_ids\"].to(device, dtype=torch.long)\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=cfg.apex):\n",
    "            outputs = model(\n",
    "                input_ids=inputs_ids,\n",
    "                attention_mask=inputs_mask,\n",
    "                labels=target_ids,\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "        \n",
    "        if i%cfg.n_accumulate==0:\n",
    "            scaler.step(optimizer)\n",
    "            scheduler.step()\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "                    \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d74835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(tokenizer, model, device, loader):\n",
    "    losses = []\n",
    "    \n",
    "    model.eval()\n",
    "     \n",
    "    for _, data in enumerate(tqdm(loader), 0):\n",
    "\n",
    "        inputs_ids = data[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        inputs_mask = data[\"attention_mask\"].to(device, dtype=torch.long)        \n",
    "        target_ids = data[\"target_ids\"].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=inputs_ids,\n",
    "            attention_mask=inputs_mask,\n",
    "            labels=target_ids,\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "747b6fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\bitzh\\Documents\\JupiterNotebooks\\AI project Zhukov Egor\\wandb\\run-20220914_104523-2033a4tp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/resquilleur/T5_FOR_QA_on_SQUAD_NU/runs/2033a4tp\" target=\"_blank\">test1</a></strong> to <a href=\"https://wandb.ai/resquilleur/T5_FOR_QA_on_SQUAD_NU\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe07f405eecb43d3a9b11601e0d43919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitzh\\anaconda3\\envs\\zhuk_home\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.5723296447318118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ad9df0cae340369a75f6d1344c4ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6631288986611632\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7116778e2a4e90be464586bf50b5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.1801313888873317\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0312868d194afbab333548826cc13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6631288986611632\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff4cefdb5fd43cd9c623c5f77dda5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.1802950676818575\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5098279d7bb4bf98822c3d8efe436b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6631288986611632\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.1803</td></tr><tr><td>val_loss</td><td>0.66313</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">test1</strong>: <a href=\"https://wandb.ai/resquilleur/T5_FOR_QA_on_SQUAD_NU/runs/2033a4tp\" target=\"_blank\">https://wandb.ai/resquilleur/T5_FOR_QA_on_SQUAD_NU/runs/2033a4tp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220914_104523-2033a4tp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "# tokenizer for encoding the text\n",
    "tokenizer = T5Tokenizer.from_pretrained(cfg.model_name)\n",
    "collate_fn = Collate(tokenizer)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(cfg.model_name).to(device)\n",
    "\n",
    "wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"T5_FOR_QA_on_SQUAD_NU\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"test1\")\n",
    "\n",
    "# формируем тренировачный набор и лоадер\n",
    "train_dataset = T5DataSet(\n",
    "    train_data,\n",
    "    tokenizer,\n",
    "    cfg.source_max_len,\n",
    "    cfg.target_max_len,\n",
    ")\n",
    "\n",
    "train_params = {\n",
    "    \"batch_size\": cfg.batch_size,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": cfg.num_workers,\n",
    "    \"collate_fn\": collate_fn,\n",
    "    \"pin_memory\": True,\n",
    "    \"drop_last\": True\n",
    "}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, **train_params)\n",
    "\n",
    "# формируем проверочный набор и лоадер\n",
    "val_dataset = T5DataSet(\n",
    "    val_data,\n",
    "    tokenizer,\n",
    "    cfg.source_max_len,\n",
    "    cfg.target_max_len,\n",
    ")\n",
    "\n",
    "val_params = {\n",
    "    \"batch_size\": cfg.batch_size * 2,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": cfg.num_workers,\n",
    "    \"collate_fn\": collate_fn,\n",
    "    \"pin_memory\": True,\n",
    "    \"drop_last\": True\n",
    "}\n",
    "\n",
    "val_loader = DataLoader(val_dataset, **val_params)\n",
    "\n",
    "# шедулер и оптимайзер\n",
    "optimizer = AdamW(model.parameters(), lr=cfg.learning_rate, eps=cfg.eps, betas=cfg.betas)\n",
    "\n",
    "num_train_steps = int(len(train_loader) / cfg.batch_size * cfg.epoch)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=cfg.num_warmup_steps,\n",
    "        num_training_steps=num_train_steps\n",
    "        )\n",
    "\n",
    "best_loss = np.inf\n",
    "for epoch in range(cfg.epoch):\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{cfg.epoch}')\n",
    "    print('-' * 10)\n",
    "    \n",
    "    train_loss = train_epoch(tokenizer, model, device, train_loader, optimizer)  \n",
    "    print(f'Train loss {train_loss}')\n",
    "    \n",
    "    val_loss = validate(tokenizer, model, device, val_loader) \n",
    "    print(f'Val   loss {val_loss}\\n')\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        # checkpoint\n",
    "        model.save_pretrained(cfg.path_of_model)\n",
    "        best_loss = val_loss\n",
    "    wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "      \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2469804",
   "metadata": {},
   "source": [
    "# 3. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ecd5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge(predictions: list, actual: list):\n",
    "    \"\"\"\n",
    "    Calculates ROUGE metrics (RU too)\n",
    "    :param predictions:\n",
    "    :param labels:\n",
    "    :return: Return dict of average of curent metrics\n",
    "    \"\"\"\n",
    "\n",
    "    assert type(predictions) == list, \"Hypotes not a list\"\n",
    "    assert type(actual) == list, \"Targets not a list\"\n",
    "\n",
    "    i = 0\n",
    "    for p in predictions:\n",
    "        if p == '' or p == '.':\n",
    "            predictions[i] = ' '\n",
    "        i+=1\n",
    "        \n",
    "    rouge = Rouge()\n",
    "    try:\n",
    "        result = rouge.get_scores(predictions, actual, avg=True)\n",
    "    except:\n",
    "        print(predictions)\n",
    "        print(actual)\n",
    "        return\n",
    "    return {k: {kk : round(vv, 2) for kk, vv in v.items()} for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e54ee08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(tokenizer, model, device, question, context, question_len):\n",
    "    \"\"\"\n",
    "    Function to get models predictions\n",
    "    \"\"\"\n",
    "    question = str(question)\n",
    "    context = str(context)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        max_length=question_len,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        truncation=\"only_second\",\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    inputs_ids = inputs[\"input_ids\"].to(device, dtype=torch.long)\n",
    "    inputs_mask = inputs[\"attention_mask\"].to(device, dtype=torch.long)        \n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs_ids,\n",
    "        attention_mask=inputs_mask,\n",
    "        num_beams=2,  \n",
    "        max_length=80,\n",
    "        repetition_penalty=2.5,\n",
    "        early_stopping=True,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "    preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "             for g in outputs][0]\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3f6e21-6c35-4d70-9210-55c44d371c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(cfg.path_of_model).to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1311bfd0-97cd-4cde-b6a7-70aef5284b0b",
   "metadata": {},
   "source": [
    "## 3.1. Val Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29da9c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В Одессе Бунин прожил почти полтора года — писал статьи для местных изданий, возглавлял литературный отдел газеты Южное слово , участвовал в деятельности основанного генералом Антоном Деникиным агентства ОСВАГ[91]. В частных разговорах он периодически упоминал о желании вступить в Добровольческую армию[92]. В интервью, данном газете Одесский листок (1918, № 120), писатель весьма резко отзывался о страшных контрастах эпохи — совпадении столетнего юбилея Тургенева с годовщиной революции[93][94]. Прозаик Иван Соколов-Микитов, общавшийся с Буниным в ту пору, рассказывал, что в Одессе Иван Алексеевич находился в крайне угнетённом состоянии[95].\n",
      " О чём говорил Бунин в интервью газете Одесский листок ?\n",
      " TRUE: о страшных контрастах эпохи\n",
      " PRED: О страшных контрастах эпохи\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = val_data.sample(1).index[0]\n",
    "question = val_data.iloc[idx]['question']\n",
    "context = val_data.iloc[idx]['context']\n",
    "answer = val_data.iloc[idx]['answers']\n",
    "\n",
    "pred = predict(tokenizer, model, device, question, context, cfg.source_max_len)\n",
    "print(context + '\\n', question + '\\n', f'TRUE: {answer}\\n', f'PRED: {pred}\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55c57522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fba895076e494a8ed7619ae3a50230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Первые упоминания о строении человеческого тел...</td>\n",
       "      <td>Где встречаются первые упоминания о строении ч...</td>\n",
       "      <td>в Древнем Египте</td>\n",
       "      <td>Древнем Египте</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Первые упоминания о строении человеческого тел...</td>\n",
       "      <td>Когда египетский врач Имхотеп впервые описал н...</td>\n",
       "      <td>В XXVII веке до н. э.</td>\n",
       "      <td>XXVII веке до н. э.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Телескоп имеет модульную структуру и содержит ...</td>\n",
       "      <td>Как называется корректирующая оптическая систе...</td>\n",
       "      <td>COSTAR</td>\n",
       "      <td>COSTAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Критики теории Вегенера поставили во главу угл...</td>\n",
       "      <td>Какая теория была отвергнута после смерти Веге...</td>\n",
       "      <td>теория дрейфа материков</td>\n",
       "      <td>теория дрейфа материков</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>При нагревании кусочки янтаря становятся очень...</td>\n",
       "      <td>Чему не уступают по красоте изделия из прессов...</td>\n",
       "      <td>изделиям из монолитных камней</td>\n",
       "      <td>изделиям из монолитных камней</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>Классическая трёхуровневая система накачки раб...</td>\n",
       "      <td>Где используется классическая трёхуровневая си...</td>\n",
       "      <td>в рубиновом лазере.</td>\n",
       "      <td>в рубиновом лазере</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>Первая платёжная карта American Express появил...</td>\n",
       "      <td>какой инвестиционный банк входил в состав Amer...</td>\n",
       "      <td>Lehman Brothers</td>\n",
       "      <td>Lehman Brothers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>Следующий альбом Heroes был во многом созвучен...</td>\n",
       "      <td>С каким альбомом был созвучен альбом Дэвида Бо...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>Одним из тех, на кого игра Данна произвела неи...</td>\n",
       "      <td>В каком техасском оркестре выступал гитарист Л...</td>\n",
       "      <td>Light Crust Doughboys</td>\n",
       "      <td>Light Crust Doughboys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>Банковское дело на территории Италии зародилос...</td>\n",
       "      <td>Когда произошло зарождение банковского дела на...</td>\n",
       "      <td>в III веке до нашей эры</td>\n",
       "      <td>в III веке до нашей эры</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5036 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Первые упоминания о строении человеческого тел...   \n",
       "1     Первые упоминания о строении человеческого тел...   \n",
       "2     Телескоп имеет модульную структуру и содержит ...   \n",
       "3     Критики теории Вегенера поставили во главу угл...   \n",
       "4     При нагревании кусочки янтаря становятся очень...   \n",
       "...                                                 ...   \n",
       "5031  Классическая трёхуровневая система накачки раб...   \n",
       "5032  Первая платёжная карта American Express появил...   \n",
       "5033  Следующий альбом Heroes был во многом созвучен...   \n",
       "5034  Одним из тех, на кого игра Данна произвела неи...   \n",
       "5035  Банковское дело на территории Италии зародилос...   \n",
       "\n",
       "                                               question  \\\n",
       "0     Где встречаются первые упоминания о строении ч...   \n",
       "1     Когда египетский врач Имхотеп впервые описал н...   \n",
       "2     Как называется корректирующая оптическая систе...   \n",
       "3     Какая теория была отвергнута после смерти Веге...   \n",
       "4     Чему не уступают по красоте изделия из прессов...   \n",
       "...                                                 ...   \n",
       "5031  Где используется классическая трёхуровневая си...   \n",
       "5032  какой инвестиционный банк входил в состав Amer...   \n",
       "5033  С каким альбомом был созвучен альбом Дэвида Бо...   \n",
       "5034  В каком техасском оркестре выступал гитарист Л...   \n",
       "5035  Когда произошло зарождение банковского дела на...   \n",
       "\n",
       "                            answers                           pred  \n",
       "0                  в Древнем Египте                 Древнем Египте  \n",
       "1             В XXVII веке до н. э.            XXVII веке до н. э.  \n",
       "2                            COSTAR                         COSTAR  \n",
       "3           теория дрейфа материков        теория дрейфа материков  \n",
       "4     изделиям из монолитных камней  изделиям из монолитных камней  \n",
       "...                             ...                            ...  \n",
       "5031            в рубиновом лазере.             в рубиновом лазере  \n",
       "5032                Lehman Brothers                Lehman Brothers  \n",
       "5033                            Low                            Low  \n",
       "5034          Light Crust Doughboys          Light Crust Doughboys  \n",
       "5035        в III веке до нашей эры        в III веке до нашей эры  \n",
       "\n",
       "[5036 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = val_data.copy()\n",
    "res = []\n",
    "for q, c in tqdm(zip(val_data['question'], val_data['context']), total=len(val_data)):\n",
    "    res.append(predict(tokenizer, model, device, q, c, cfg.source_max_len))\n",
    "results['pred'] = res\n",
    "results                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724ee1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.6, 'p': 0.59, 'f': 0.58},\n",
       " 'rouge-2': {'r': 0.45, 'p': 0.45, 'f': 0.43},\n",
       " 'rouge-l': {'r': 0.6, 'p': 0.59, 'f': 0.57}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rouge(results['pred'].tolist(), results['answer'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b4cb01-c7a0-4c7a-927c-913d14c95062",
   "metadata": {},
   "source": [
    "## 3.2. Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3314a1dd-947a-41f2-aa0c-da399dc7dff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В Сан-Марино существует республиканская форма правления. Главами государства являются два капитана-регента, назначаемые Большим Генеральным советом. Капитаны-регенты избираются на срок 6 месяцев, с 1 апреля до 1 октября и с 1 октября до 1 апреля каждого года. Они выполняют функции главы государства и осуществляют исполнительную власть. Большой Генеральный Совет является парламентом Республики, он состоит из 60 депутатов, избираемых всеобщим голосованием по системе пропорционального представительства сроком на 5 лет. Аренго, или ассамблея глав семейств, в древности было верховным органом, в настоящее время аренго сохранило за собой право модифицировать Статуты Республики и право петиции . Это последнее право используется и в наши дни — капитаны-регенты получают многочисленные прошения, предоставляемые гражданами в первое воскресенье после 1-го апреля и после 1-го октября. Поданные прошения в обязательном порядке должны быть рассмотрены в течение 6 месяцев.\n",
      " Какая форма правления в Сан-Марино?\n",
      " TRUE: республиканская форма правления\n",
      " PRED: республиканская форма правления\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = train_data.sample(1).index[0]\n",
    "question = train_data.iloc[idx]['question']\n",
    "context = train_data.iloc[idx]['context']\n",
    "answer = train_data.iloc[idx]['answers']\n",
    "\n",
    "pred = predict(tokenizer, model, device, question, context, cfg.source_max_len)\n",
    "print(context + '\\n', question + '\\n', f'TRUE: {answer}\\n', f'PRED: {pred}\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cac42866-5324-4067-ab6d-0576bf4d37b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12074c9e5bc44425af1df5b06e7355b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>Румы́нский язы́к (самоназвание — Limba română,...</td>\n",
       "      <td>Как еще именуется румынский язык?</td>\n",
       "      <td>В сравнительной лингвистике именуется также да...</td>\n",
       "      <td>Дако-румынским</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32178</th>\n",
       "      <td>Артикль обеспечивает связность текста (дискурс...</td>\n",
       "      <td>В каком предложении последовательного повество...</td>\n",
       "      <td>первом</td>\n",
       "      <td>в первом предложении</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41550</th>\n",
       "      <td>Во Франции пластика продолжала держаться парад...</td>\n",
       "      <td>Кто прославился колоссальною статуей Свободы ,...</td>\n",
       "      <td>А. Бартольди</td>\n",
       "      <td>Вольтер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42711</th>\n",
       "      <td>Основные фонды относятся к производственным ак...</td>\n",
       "      <td>Сколько должна быть минимальная цена объекта, ...</td>\n",
       "      <td>40 000 рублей</td>\n",
       "      <td>пятидесятикратной установленной законом минима...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29309</th>\n",
       "      <td>Большинство транспортных средств оснащены двиг...</td>\n",
       "      <td>какими двигателями оснащены большинство трансп...</td>\n",
       "      <td>двигателями внутреннего сгорания</td>\n",
       "      <td>двигателями внутреннего сгорания</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25594</th>\n",
       "      <td>Классиками и отцами-основателями киберпанка на...</td>\n",
       "      <td>Когда жанр киберпанка набрал популярность?</td>\n",
       "      <td>В 90-е</td>\n",
       "      <td>90-е годы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24815</th>\n",
       "      <td>Во II веке до н. э. на Форуме стали всё больше...</td>\n",
       "      <td>Как диктатор Сулла назвал новую курию?</td>\n",
       "      <td>Корнелия</td>\n",
       "      <td>курия Корнелия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39867</th>\n",
       "      <td>Благодаря реализации проектов СРП, Сахалинская...</td>\n",
       "      <td>Какая область находится на пятой строчке росси...</td>\n",
       "      <td>Сахалинская область</td>\n",
       "      <td>Сахалинская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>Химические остатки пива, датированные 3500—310...</td>\n",
       "      <td>Что получали строители египетских пирамид полу...</td>\n",
       "      <td>пиво</td>\n",
       "      <td>пиво</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36406</th>\n",
       "      <td>Предложен изобретателем Ванкелем в начале ХХ в...</td>\n",
       "      <td>Кем изобретен двигатель внутреннего сгорания?</td>\n",
       "      <td>изобретателем Ванкелем</td>\n",
       "      <td>Ванкелем в начале ХХ века</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 context  \\\n",
       "3850   Румы́нский язы́к (самоназвание — Limba română,...   \n",
       "32178  Артикль обеспечивает связность текста (дискурс...   \n",
       "41550  Во Франции пластика продолжала держаться парад...   \n",
       "42711  Основные фонды относятся к производственным ак...   \n",
       "29309  Большинство транспортных средств оснащены двиг...   \n",
       "...                                                  ...   \n",
       "25594  Классиками и отцами-основателями киберпанка на...   \n",
       "24815  Во II веке до н. э. на Форуме стали всё больше...   \n",
       "39867  Благодаря реализации проектов СРП, Сахалинская...   \n",
       "7609   Химические остатки пива, датированные 3500—310...   \n",
       "36406  Предложен изобретателем Ванкелем в начале ХХ в...   \n",
       "\n",
       "                                                question  \\\n",
       "3850                   Как еще именуется румынский язык?   \n",
       "32178  В каком предложении последовательного повество...   \n",
       "41550  Кто прославился колоссальною статуей Свободы ,...   \n",
       "42711  Сколько должна быть минимальная цена объекта, ...   \n",
       "29309  какими двигателями оснащены большинство трансп...   \n",
       "...                                                  ...   \n",
       "25594         Когда жанр киберпанка набрал популярность?   \n",
       "24815             Как диктатор Сулла назвал новую курию?   \n",
       "39867  Какая область находится на пятой строчке росси...   \n",
       "7609   Что получали строители египетских пирамид полу...   \n",
       "36406      Кем изобретен двигатель внутреннего сгорания?   \n",
       "\n",
       "                                                 answers  \\\n",
       "3850   В сравнительной лингвистике именуется также да...   \n",
       "32178                                             первом   \n",
       "41550                                       А. Бартольди   \n",
       "42711                                      40 000 рублей   \n",
       "29309                   двигателями внутреннего сгорания   \n",
       "...                                                  ...   \n",
       "25594                                             В 90-е   \n",
       "24815                                           Корнелия   \n",
       "39867                                Сахалинская область   \n",
       "7609                                                пиво   \n",
       "36406                             изобретателем Ванкелем   \n",
       "\n",
       "                                                    pred  \n",
       "3850                                      Дако-румынским  \n",
       "32178                               в первом предложении  \n",
       "41550                                            Вольтер  \n",
       "42711  пятидесятикратной установленной законом минима...  \n",
       "29309                   двигателями внутреннего сгорания  \n",
       "...                                                  ...  \n",
       "25594                                          90-е годы  \n",
       "24815                                     курия Корнелия  \n",
       "39867                                Сахалинская область  \n",
       "7609                                                пиво  \n",
       "36406                          Ванкелем в начале ХХ века  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_t = train_data.sample(2000).copy()\n",
    "res = []\n",
    "for q, c in tqdm(zip(results_t['question'], results_t['context']), total=len(results_t)):\n",
    "    res.append(predict(tokenizer, model, device, q, c, cfg.source_max_len))\n",
    "results_t['pred'] = res\n",
    "results_t    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19ab336d-643e-49b9-9ad9-8b7fa6e16b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.66, 'p': 0.66, 'f': 0.64},\n",
       " 'rouge-2': {'r': 0.47, 'p': 0.48, 'f': 0.46},\n",
       " 'rouge-l': {'r': 0.66, 'p': 0.66, 'f': 0.64}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rouge(results_t['pred'].tolist(), results_t['answers'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ced15",
   "metadata": {},
   "source": [
    "# 4. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d3290",
   "metadata": {},
   "source": [
    "На текущий момент нет достойных метрик для определения качества обучения по данной задачи, теорритически им может стать рейтинг удолетворенности ответом в будущем. \n",
    "\n",
    "ель в первую очередь добится качественного повторения ответов из контекста, поэтому большинство ответов будет данно модели при обучение, но и с валидацией она справляется, хоть часть контекста и присуствует на обучение. \n",
    "\n",
    "Считаю текущий результат дойстойным и действенным. Дальнейшее улучшение возможно при увеличение выборки, сужении домена контекстов и замены модели на более бОльшую."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhuk_home",
   "language": "python",
   "name": "zhuk_home"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
